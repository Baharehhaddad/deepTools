#!/usr/bin/env python
#-*- coding: utf-8 -*-

import numpy as np
# own tools
import argparse
from deeptools import writeBedGraph
from deeptools import parserCommon
from deeptools import bamHandler

debug = 0

def parseArguments(args=None):

    parentParser = parserCommon.getParentArgParse()
    bamParser = parserCommon.bam()
    outputParser = parserCommon.output()
    parser = argparse.ArgumentParser(parents=[parentParser, bamParser, outputParser],
                                     formatter_class=argparse.ArgumentDefaultsHelpFormatter,
                                     description = 'Given a BAM file, this tool generates a coverage bigWig file. '
                                     'The method first calculates the number of reads (either extended or not) that '
                                     'overlap each tile (or bin) in the genome. Tiles with counts equal to zero are skipped, '
                                     'i.e. not added to the output file.\n'
                                     'The resulting read counts can be normalized using a given scaling factor, either using '
                                     'the RPKM formula or normalizing to 1x depth of coverage.\n')

    # define the arguments
    parser.add_argument('--bam', '-b',
                        help = 'BAM file to process',
                        metavar = 'BAM file',
                        required = True)

    parser.add_argument('--bamIndex', '-bai',
                        help = 'Index for the BAM file. Default is to consider the path of the BAM file adding the .bai suffix.',
                        metavar = 'BAM file index')


    parser.add_argument('--mappedReads',
                        help = "Use this number of mapped reads instead of the value determined from the BAM file ",
                        type = int)

    parser.add_argument('--normalizeTo1x',
                          help='Report read coverage normalized to 1x '
                          'sequencing depth (also known as Reads Per Genomic '
                          'Content (RPGC)). Sequencing depth is defined as: '
                          '(total number of mapped reads * fragment length) / '
                          'effective genome size.\nThe scaling factor used '
                          'is the inverse of the sequencing depth computed '
                          'for the sample to match the 1x coverage. '
                          'To use this option, the '
                          'effective genome size has to be indicated after the '
                          'option. The effective genome size is the portion '
                          'of the genome that is mappable. Large fractions of '
                          'the genome are stretches of NNNN that should be '
                          'discarded. Also, if repetitive regions were not '
                          'included in the mapping of reads, the effective '
                          'genome size needs to be adjusted accordingly. '
                          'Common values are: mm9: 2,150,570,000; '
                          'hg19:2,451,960,000; dm3:121,400,000 and ce10:93,260,000. '
                          'See Table 2 of http://www.plosone.org/article/info:doi/10.1371/journal.pone.0030377 ' 
                          'or http://www.nature.com/nbt/journal/v27/n1/fig_tab/nbt.1518_T1.html '
                          'for several effective genome sizes.',
                          metavar='EFFECTIVE GENOME SIZE LENGTH',
                          default=None,
                          type=int,
                          required=False)

    parser.add_argument('--normalizeUsingRPKM',
                          help='Use Reads Per Kilobase per Million reads to '
                          'normalize the number of reads per bin. The formula '
                          'is: RPKM (per bin) =  number of reads per bin / '
                          '( number of mapped reads (in millions) * bin '
                          'length (kb) ). Each read is considered independently,'
                          'if you want to only count either of the mate pairs in'
                          'paired-end data, use the --samFlag option.',
                          action='store_true',
                          required=False)

    args = parser.parse_args(args)


    return(args)

def scaleFactor(string):
    try:
        scaleFactor1, scaleFactor2 = string.split(":")
        scaleFactors = ( float(scaleFactor1), float(scaleFactor2) )
    except:
        raise argparse.ArgumentTypeError("Format of scaleFactors is factor1:factor2. The value given ( {} ) is not valid".format(string))
    return scaleFactors


def getFragmentCenter(read, defaultFragmentLength, extendPairedEnds=True, 
                      maxPairedFragmentLength=None):
    
    """
    Takes a proper pair fragment of high quality and limited
    to a certain length and outputs the center
    """
    fragmentStart = fragmentEnd = None
    
    if not maxPairedFragmentLength:
        maxPairedFragmentLength = 2*defaultFragmentLength if defaultFragmentLength > 0 else 1000;

    # only paired forward reads are considered
    if read.is_proper_pair and not read.is_reverse \
            and abs(read.tlen) < 250 and read.mapq > 10:

        if read.tlen % 2 == 0:
            fragmentStart = read.pos + read.tlen/2 -1
            fragmentEnd   = fragmentStart + 2
            
        else:
            fragmentStart = read.pos + read.tlen/2 - 1
            fragmentEnd   = fragmentStart + 3
            
    return (fragmentStart, fragmentEnd)

#######################################
# MAIN

def main(args):
    bamFile = args.bam
    bamHandle = bamHandler.openBam(args.bam, args.bamIndex)
    binSize = args.binSize if args.binSize > 0 else 50
    fragmentLength = args.fragmentLength if args.fragmentLength >0 else 300

    chunkSize = int(50e6)

    global debug
    if args.verbose:
        debug = 1
    else:
        debug = 0

    if not args.mappedReads:
        args.mappedReads = bamHandle.mapped
    
    if args.normalizeTo1x:
        current_coverage = float(args.mappedReads * fragmentLength) / args.normalizeTo1x
        # the scaling sets the coverage to match 1x
        args.scaleFactor = 1.0 / current_coverage
        if debug:
            print "Estimated current coverage {}".format(current_coverage)
            print "Scaling factor {}".format(args.scaleFactor)

    elif args.normalizeUsingRPKM:
        # the RPKM is the # reads per tile / ( total reads (in millions) * tile length in Kb)
        millionReadsMapped = float(args.mappedReads)  / 1e6
        tileLengthInKb = float(args.binSize) / 1000
        args.scaleFactor =  1.0 / (millionReadsMapped * tileLengthInKb )
        if debug:
            print "scale factor using RPKM is {0}".format(args.scaleFactor)
    else:
        args.scaleFactor = 1

    funcArgs = {'scaleFactor': args.scaleFactor}


    wr = writeBedGraph.WriteBedGraph([bamHandle.filename], binSize, 0,
                                    fragmentLength,
                                    stepSize=binSize,
                                    region=args.region,
                                    numberOfProcessors=args.numberOfProcessors,
                                    extendPairedEnds=args.extendPairedEnds,
                                    minMappingQuality=args.minMappingQuality,
                                    ignoreDuplicates=args.ignoreDuplicates,
                                    center_read=args.centerReads,
                                    zerosToNans=True,
                                    samFlag=args.samFlag)

    wr.run(writeBedGraph.scaleCoverage, funcArgs,  args.outFileName,
            format=args.outFileFormat, smooth_length=args.smoothLength)

    
if __name__ == "__main__":
    args = parseArguments()
    main(args)
